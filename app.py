# app.py
import streamlit as st
import PyPDF2
from sentence_transformers import SentenceTransformer, util
import openai

# Ù„Ùˆ Ù…Ø¹Ø§Ùƒ GPT API key
openai.api_key = "YOUR_OPENAI_API_KEY"

st.title("Pixels StudyMate ğŸ“˜ğŸ¤–")
st.write("Ù…Ø³Ø§Ø¹Ø¯Ùƒ Ø§Ù„Ø°ÙƒÙŠ Ù„Ù„Ù…Ø°Ø§ÙƒØ±Ø© ÙˆÙÙ‡Ù… Ù…Ù„ÙØ§Øª Ø§Ù„Ø¯Ø±Ø§ÙŠÙ")

uploaded_file = st.file_uploader("Ø§Ø±ÙØ¹ Ù…Ù„Ù PDF", type="pdf")
question = st.text_input("Ø§ÙƒØªØ¨ Ø³Ø¤Ø§Ù„Ùƒ Ù‡Ù†Ø§:")

if uploaded_file:
    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ù…Ù† PDF
    reader = PyPDF2.PdfReader(uploaded_file)
    text = ""
    for page in reader.pages:
        text += page.extract_text()

    # ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ ÙÙ‚Ø±Ø§Øª ØµØºÙŠØ±Ø©
    chunks = text.split("\n")
    model = SentenceTransformer('all-MiniLM-L6-v2')
    embeddings = model.encode(chunks, convert_to_tensor=True)

    if question:
        # Ø¨Ø­Ø« Ø¯Ù„Ø§Ù„ÙŠ Ø¹Ù† Ø§Ù„ÙÙ‚Ø±Ø© Ø§Ù„Ø£Ù‚Ø±Ø¨
        q_embed = model.encode(question, convert_to_tensor=True)
        scores = util.pytorch_cos_sim(q_embed, embeddings)[0]
        best_idx = scores.argmax()
        context = chunks[best_idx]

        # ØªÙˆÙ„ÙŠØ¯ Ø¥Ø¬Ø§Ø¨Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… GPT (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)
        response = openai.ChatCompletion.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø¯Ø±Ø§Ø³ÙŠ Ø°ÙƒÙŠ Ù„Ø·Ù„Ø¨Ø© Ù‡Ù†Ø¯Ø³Ø©."},
                {"role": "user", "content": f"Ø§Ù„Ø³Ø¤Ø§Ù„: {question}\n\nØ§Ù„Ù…ØµØ¯Ø±: {context}"}
            ]
        )
        answer = response['choices'][0]['message']['content']
        st.markdown("### ğŸ¤– Ø¥Ø¬Ø§Ø¨Ø© Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯:")
        st.write(answer)
